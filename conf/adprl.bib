@inproceedings{conf/adprl/SeijenHWW09,
  title = {A theoretical and empirical analysis of Expected Sarsa},
  pages = {177-184},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927542},
  crossref = {conf/adprl/2009},
  author = {Harm van Seijen and Hado van Hasselt and Shimon Whiteson and Marco A. Wiering}
}
@inproceedings{conf/adprl/WieringHPS11,
  title = {Reinforcement learning algorithms for solving classification problems},
  pages = {91-96},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967372},
  crossref = {conf/adprl/2011},
  author = {Marco A. Wiering and Hado van Hasselt and Auke-Dirk Pietersma and Lambert Schomaker}
}
@inproceedings{conf/adprl/ZhangZCL11,
  title = {Global optimal strategies of a class of finite-horizon continuous-time nonaffine nonlinear zero-sum game using a new iteration algorithm},
  pages = {196-201},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967360},
  crossref = {conf/adprl/2011},
  author = {Xin Zhang and Huaguang Zhang and Lili Cui and Yanhong Luo}
}
@inproceedings{conf/adprl/MoffaertDN13,
  title = {Scalarized multi-objective reinforcement learning: Novel design techniques},
  pages = {191-199},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6615007},
  crossref = {conf/adprl/2013},
  author = {Kristof Van Moffaert and Madalina M. Drugan and Ann Nowé}
}
@inproceedings{conf/adprl/HansDU11,
  title = {Agent self-assessment: Determining policy quality without execution},
  pages = {84-90},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967358},
  crossref = {conf/adprl/2011},
  author = {Alexander Hans and Siegmund Duell and Steffen Udluft}
}
@inproceedings{conf/adprl/LiuWZ11,
  title = {Adaptive dynamic programming for optimal control of unknown nonlinear discrete-time systems},
  pages = {242-249},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967357},
  crossref = {conf/adprl/2011},
  author = {Derong Liu and Ding Wang and Dongbin Zhao}
}
@inproceedings{conf/adprl/RyzhovP09,
  title = {The knowledge gradient algorithm for online subset selection},
  pages = {137-144},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927537},
  crossref = {conf/adprl/2009},
  author = {Ilya O. Ryzhov and Warren B. Powell}
}
@inproceedings{conf/adprl/BoukhtoutaBPG11,
  title = {An adaptive-learning framework for semi-cooperative multi-agent coordination},
  pages = {324-331},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967386},
  crossref = {conf/adprl/2011},
  author = {Abdeslem Boukhtouta and Jean Berger and Warren B. Powell and Abraham P. George}
}
@inproceedings{conf/adprl/ZhaoH11,
  title = {Supervised adaptive dynamic programming based adaptive cruise control},
  pages = {318-323},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967371},
  crossref = {conf/adprl/2011},
  author = {Dongbin Zhao and Zhaohui Hu}
}
@inproceedings{conf/adprl/GeistPF09,
  title = {Kalman Temporal Differences: The deterministic case},
  pages = {185-192},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927543},
  crossref = {conf/adprl/2009},
  author = {Matthieu Geist and Olivier Pietquin and Gabriel Fricout}
}
@inproceedings{conf/adprl/DefournyEW09,
  title = {Planning under uncertainty, ensembles of disturbance trees and kernelized discrete action spaces},
  pages = {145-152},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927538},
  crossref = {conf/adprl/2009},
  author = {Boris Defourny and Damien Ernst and Louis Wehenkel}
}
@inproceedings{conf/adprl/SongXL13,
  title = {Optimal control for a class of nonlinear system with controller constraints based on finite-approximation-errors ADP algorithm},
  pages = {19-23},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614984},
  crossref = {conf/adprl/2013},
  author = {Ruizhuo Song and Wendong Xiao and Yanhong Luo}
}
@inproceedings{conf/adprl/BraunOTS11,
  title = {Path integral control and bounded rationality},
  pages = {202-209},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967366},
  crossref = {conf/adprl/2011},
  author = {Daniel A. Braun and Pedro A. Ortega and Evangelos Theodorou and Stefan Schaal}
}
@inproceedings{conf/adprl/Belavkin09,
  title = {Bounds of optimal learning},
  pages = {199-204},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927545},
  crossref = {conf/adprl/2009},
  author = {Roman V. Belavkin}
}
@inproceedings{conf/adprl/Nanduri11,
  title = {Application of reinforcement learning-based algorithms in CO2 allowance and electricity markets},
  pages = {164-169},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967367},
  crossref = {conf/adprl/2011},
  author = {Vishnuteja Nanduri}
}
@inproceedings{conf/adprl/BusoniuDMB13,
  title = {Optimistic planning for continuous-action deterministic systems},
  pages = {69-76},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614991},
  crossref = {conf/adprl/2013},
  author = {Lucian Busoniu and A. Daniels and Rémi Munos and Robert Babuska}
}
@inproceedings{conf/adprl/ZhaoXJ13,
  title = {Finite-horizon optimal control design for uncertain linear discrete-time systems},
  pages = {6-12},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614982},
  crossref = {conf/adprl/2013},
  author = {Qiming Zhao and Hao Xu and Sarangapani Jagannathan}
}
@inproceedings{conf/adprl/Awate09,
  title = {Algorithms for variance reduction in a policy-gradient based actor-critic framework},
  pages = {130-136},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927536},
  crossref = {conf/adprl/2009},
  author = {Yogesh P. Awate}
}
@inproceedings{conf/adprl/AwhedaS13,
  title = {Exponential moving average Q-learning algorithm},
  pages = {31-38},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614986},
  crossref = {conf/adprl/2013},
  author = {Mostafa D. Awheda and Howard M. Schwartz}
}
@inproceedings{conf/adprl/PanT14,
  title = {Nonparametric infinite horizon Kullback-Leibler stochastic control},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010616},
  crossref = {conf/adprl/2014},
  author = {Yunpeng Pan and Evangelos A. Theodorou}
}
@proceedings{conf/adprl/2009,
  title = {IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning, ADPRL 2009, Nashville, TN, USA, March 31 - April 1, 2009},
  publisher = {IEEE},
  year = {2009},
  booktitle = {ADPRL},
  isbn = {978-1-4244-2761-1},
  url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=4910084},
  author = {}
}
@inproceedings{conf/adprl/GarrettBT14,
  title = {Tunable and generic problem instance generation for multi-objective reinforcement learning},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010646},
  crossref = {conf/adprl/2014},
  author = {Deon Garrett and Jordi Bieger and Kristinn R. Thórisson}
}
@inproceedings{conf/adprl/ZhangHL09,
  title = {Algorithm and stability of ATC receding horizon control},
  pages = {28-35},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927522},
  crossref = {conf/adprl/2009},
  author = {Hongwei Zhang and Jie Huang 0001 and Frank L. Lewis}
}
@inproceedings{conf/adprl/GeistP11,
  title = {Parametric value function approximation: A unified view},
  pages = {9-16},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967355},
  crossref = {conf/adprl/2011},
  author = {Matthieu Geist and Olivier Pietquin}
}
@inproceedings{conf/adprl/SahooXJ14,
  title = {Event-based optimal regulator design for nonlinear networked control systems},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010634},
  crossref = {conf/adprl/2014},
  author = {Avimanyu Sahoo and Hao Xu and Sarangapani Jagannathan}
}
@inproceedings{conf/adprl/ReeW13,
  title = {Reinforcement learning in the game of Othello: Learning against a fixed opponent and learning from self-play},
  pages = {108-115},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614996},
  crossref = {conf/adprl/2013},
  author = {M. van der Ree and Marco Wiering}
}
@inproceedings{conf/adprl/YuB09,
  title = {Basis function adaptation methods for cost approximation in MDP},
  pages = {74-81},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927528},
  crossref = {conf/adprl/2009},
  author = {Huizhen Yu and Dimitri P. Bertsekas}
}
@inproceedings{conf/adprl/PreuxGL09,
  title = {Feature discovery in approximate dynamic programming},
  pages = {109-116},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927533},
  crossref = {conf/adprl/2009},
  author = {Philippe Preux and Sertan Girgin and Manuel Loth}
}
@inproceedings{conf/adprl/LinCL13,
  title = {Optimal control for a class of nonlinear systems with state delay based on Adaptive Dynamic Programming with ε-error bound},
  pages = {177-182},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6615005},
  crossref = {conf/adprl/2013},
  author = {Xiaofeng Lin and Nuyun Cao and Yuzhang Lin}
}
@inproceedings{conf/adprl/YasudaWOM13,
  title = {Analyzing collective behavior in evolutionary swarm robotic systems based on an ethological approach},
  pages = {148-155},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6615001},
  crossref = {conf/adprl/2013},
  author = {Toshiyuki Yasuda and Nanami Wada and Kazuhiro Ohkura and Yoshiyuki Matsumura}
}
@inproceedings{conf/adprl/TheodorouNT13,
  title = {Free energy based policy gradients},
  pages = {124-131},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614998},
  crossref = {conf/adprl/2013},
  author = {Evangelos Theodorou and Jiri Najemnik and Emanuel Todorov}
}
@inproceedings{conf/adprl/ReindorpF11,
  title = {Dynamic lead time promising},
  pages = {176-183},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967376},
  crossref = {conf/adprl/2011},
  author = {Matthew J. Reindorp and Michael C. Fu}
}
@inproceedings{conf/adprl/HuangZY13,
  title = {Local stability analysis of high-order recurrent neural networks with multi-step piecewise linear activation functions},
  pages = {1-5},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614981},
  crossref = {conf/adprl/2013},
  author = {Yujiao Huang and Huaguang Zhang and Dongsheng Yang}
}
@inproceedings{conf/adprl/SimpkinsT11,
  title = {Complex object manipulation with hierarchical optimal control},
  pages = {338-345},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967393},
  crossref = {conf/adprl/2011},
  author = {Alex Simpkins and Emanuel Todorov}
}
@inproceedings{conf/adprl/LiuT09,
  title = {Hierarchical optimal control of a 7-DOF arm model},
  pages = {50-57},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927525},
  crossref = {conf/adprl/2009},
  author = {Dan Liu and Emanuel Todorov}
}
@inproceedings{conf/adprl/TengT13,
  title = {Delayed insertion and rule effect moderation of domain knowledge for reinforcement learning},
  pages = {132-139},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614999},
  crossref = {conf/adprl/2013},
  author = {Teck-Hou Teng and Ah-Hwee Tan}
}
@inproceedings{conf/adprl/LiuXHD11,
  title = {Adaptive sample collection using active learning for kernel-based approximate policy iteration},
  pages = {56-61},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967377},
  crossref = {conf/adprl/2011},
  author = {Chunming Liu and Xin Xu and Haiyun Hu and Bin Dai}
}
@inproceedings{conf/adprl/MigliavaccaPPRB11,
  title = {Fitted policy search},
  pages = {287-294},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967368},
  crossref = {conf/adprl/2011},
  author = {Martino Migliavacca and Alessio Pecorino and Matteo Pirotta and Marcello Restelli and Andrea Bonarini}
}
@inproceedings{conf/adprl/FuHN11,
  title = {Adaptive dynamic programming with balanced weights seeking strategy},
  pages = {210-217},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967373},
  crossref = {conf/adprl/2011},
  author = {Jian Fu and Haibo He and Zhen Ni}
}
@inproceedings{conf/adprl/StinguL11,
  title = {An approximate Dynamic Programming based controller for an underactuated 6DoF quadrotor},
  pages = {271-278},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967394},
  crossref = {conf/adprl/2011},
  author = {Petru Emanuel Stingu and Frank L. Lewis}
}
@inproceedings{conf/adprl/TheodorouBS09,
  title = {Path integral-based stochastic optimal control for rigid body dynamics},
  pages = {219-225},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927548},
  crossref = {conf/adprl/2009},
  author = {Evangelos Theodorou and Jonas Buchli and Stefan Schaal}
}
@proceedings{conf/adprl/2011,
  title = {2011 IEEE Symposium on Adaptive Dynamic Programming And Reinforcement Learning, ADPRL 2011, Paris, France, April 12-14, 2011},
  publisher = {IEEE},
  year = {2011},
  booktitle = {ADPRL},
  isbn = {978-1-4244-9888-8},
  url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=5958170},
  author = {}
}
@inproceedings{conf/adprl/FonteneauBM13,
  title = {Optimistic planning for belief-augmented Markov Decision Processes},
  pages = {77-84},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614992},
  crossref = {conf/adprl/2013},
  author = {Raphaël Fonteneau and Lucian Busoniu and Rémi Munos}
}
@inproceedings{conf/adprl/XuJ14,
  title = {Model-free Q-learning over finite horizon for uncertain linear continuous-time systems},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010629},
  crossref = {conf/adprl/2014},
  author = {Hao Xu and Sarangapani Jagannathan}
}
@inproceedings{conf/adprl/ZhongNTH14,
  title = {Data-driven partially observable dynamic processes using adaptive dynamic programming},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010628},
  crossref = {conf/adprl/2014},
  author = {Xiangnan Zhong and Zhen Ni and Yufei Tang and Haibo He}
}
@inproceedings{conf/adprl/BaiZY09,
  title = {ADHDP(λ) strategies based coordinated ramps metering with queuing consideration},
  pages = {22-27},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927521},
  crossref = {conf/adprl/2009},
  author = {Xuerui Bai and Dongbin Zhao and Jianqiang Yi}
}
@inproceedings{conf/adprl/BusoniuMP14,
  title = {An analysis of optimistic, best-first search for minimax sequential decision making},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010615},
  crossref = {conf/adprl/2014},
  author = {Lucian Busoniu and Rémi Munos and Elod Pall}
}
@inproceedings{conf/adprl/YahyaaDM14,
  title = {Annealing-pareto multi-objective multi-armed bandit algorithm},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010619},
  crossref = {conf/adprl/2014},
  author = {Saba Q. Yahyaa and Madalina M. Drugan and Bernard Manderick}
}
@inproceedings{conf/adprl/WuYZ14,
  title = {Adaptive fault identification for a class of nonlinear dynamic systems},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010635},
  crossref = {conf/adprl/2014},
  author = {Li-Bing Wu and Dan Ye and Xin-Gang Zhao}
}
@inproceedings{conf/adprl/ColletP14,
  title = {Active learning for classification: An optimistic approach},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010610},
  crossref = {conf/adprl/2014},
  author = {Timothé Collet and Olivier Pietquin}
}
@inproceedings{conf/adprl/Francois-LavetFE14,
  title = {Using approximate dynamic programming for estimating the revenues of a hydrogen-based high-capacity storage device},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010624},
  crossref = {conf/adprl/2014},
  author = {Vincent François-Lavet and Raphaël Fonteneau and Damien Ernst}
}
@inproceedings{conf/adprl/ArslanTT14,
  title = {Information-theoretic stochastic optimal control via incremental sampling-based algorithms},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010617},
  crossref = {conf/adprl/2014},
  author = {Oktay Arslan and Evangelos A. Theodorou and Panagiotis Tsiotras}
}
@inproceedings{conf/adprl/KroemerP11,
  title = {Active exploration for robot parameter selection in episodic reinforcement learning},
  pages = {25-31},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967378},
  crossref = {conf/adprl/2011},
  author = {Oliver Kroemer and Jan Peters 0001}
}
@inproceedings{conf/adprl/FonteneauMWE09,
  title = {Inferring bounds on the performance of a control policy from a sample of trajectories},
  pages = {117-123},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927534},
  crossref = {conf/adprl/2009},
  author = {Raphaël Fonteneau and Susan A. Murphy and Louis Wehenkel and Damien Ernst}
}
@inproceedings{conf/adprl/GabelLR11,
  title = {Improved neural fitted Q iteration applied to a novel computer gaming and learning benchmark},
  pages = {279-286},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967361},
  crossref = {conf/adprl/2011},
  author = {Thomas Gabel and Christian Lutz and Martin A. Riedmiller}
}
@inproceedings{conf/adprl/FeinbergKZ14,
  title = {Convergence of value iterations for total-cost MDPs and POMDPs with general state and action sets},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010613},
  crossref = {conf/adprl/2014},
  author = {Eugene A. Feinberg and Pavlo O. Kasyanov and Michael Z. Zgurovsky}
}
@inproceedings{conf/adprl/Heydari14,
  title = {Theoretical analysis of a reinforcement learning based switching scheme},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010614},
  crossref = {conf/adprl/2014},
  author = {Ali Heydari}
}
@inproceedings{conf/adprl/SunTT14,
  title = {Continuous-time differential dynamic programming with terminal constraints},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010647},
  crossref = {conf/adprl/2014},
  author = {Wei Sun and Evangelos A. Theodorou and Panagiotis Tsiotras}
}
@inproceedings{conf/adprl/DijkP11,
  title = {Grounding subgoals in information transitions},
  pages = {105-111},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967384},
  crossref = {conf/adprl/2011},
  author = {Sander G. van Dijk and Daniel Polani}
}
@inproceedings{conf/adprl/CastellettiGRS11,
  title = {Tree-based variable selection for dimensionality reduction of large-scale control systems},
  pages = {62-69},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967387},
  crossref = {conf/adprl/2011},
  author = {Andrea Castelletti and Stefano Galelli and Marcello Restelli and Rodolfo Soncini-Sessa}
}
@inproceedings{conf/adprl/GosaviDM14,
  title = {Beyond exponential utility functions: A variance-adjusted approach for risk-averse reinforcement learning},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010645},
  crossref = {conf/adprl/2014},
  author = {Abhijit Gosavi and Sajal K. Das and Susan L. Murray}
}
@inproceedings{conf/adprl/ElliottA14,
  title = {Using supervised training signals of observable state dynamics to speed-up and improve reinforcement learning},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010640},
  crossref = {conf/adprl/2014},
  author = {Daniel L. Elliott and Charles W. Anderson}
}
@inproceedings{conf/adprl/Garcia-PoloF11,
  title = {Safe reinforcement learning in high-risk tasks through policy improvement},
  pages = {76-83},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967356},
  crossref = {conf/adprl/2011},
  author = {Francisco Javier García-Polo and Fernando Fernández-Rebollo}
}
@inproceedings{conf/adprl/BoedeckerSWR14,
  title = {Approximate real-time optimal control based on sparse Gaussian process models},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010608},
  crossref = {conf/adprl/2014},
  author = {Joschka Boedecker and Jost Tobias Springenberg and Jan Wülfing and Martin A. Riedmiller}
}
@inproceedings{conf/adprl/WeiLSLG14,
  title = {Optimal self-learning battery control in smart residential grids by iterative Q-learning algorithm},
  pages = {1-7},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010630},
  crossref = {conf/adprl/2014},
  author = {Qinglai Wei and Derong Liu and Guang Shi and Yu Liu and Qiang Guan}
}
@inproceedings{conf/adprl/Lendaris11,
  title = {Higher-level application of Adaptive Dynamic Programming/Reinforcement Learning - a next phase for controls and system identification?},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967395},
  crossref = {conf/adprl/2011},
  author = {George G. Lendaris}
}
@inproceedings{conf/adprl/ZhongJTET13,
  title = {Value function approximation and model predictive control},
  pages = {100-107},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614995},
  crossref = {conf/adprl/2013},
  author = {Mingyuan Zhong and M. Johnson and Yuval Tassa and Tom Erez and Emo Todorov}
}
@inproceedings{conf/adprl/LiuLZ14,
  title = {Adaptive dynamic programming for discrete-time LQR optimal tracking control problems with unknown dynamics},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010636},
  crossref = {conf/adprl/2014},
  author = {Yang Liu and Yanhong Luo and Huaguang Zhang}
}
@inproceedings{conf/adprl/PatinoTC09,
  title = {Adaptive Critic Designs-based autonomous unmanned vehicles navigation: Application to robotic farm vehicles},
  pages = {233-237},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927550},
  crossref = {conf/adprl/2009},
  author = {H. Daniel Patiño and Santiago Tosetti and Flavio Capraro}
}
@inproceedings{conf/adprl/BomHW13,
  title = {Reinforcement learning to train Ms. Pac-Man using higher-order action-relative inputs},
  pages = {156-163},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6615002},
  crossref = {conf/adprl/2013},
  author = {Luuk Bom and Ruud Henken and Marco Wiering}
}
@inproceedings{conf/adprl/RobertsMT11,
  title = {Feedback controller parameterizations for Reinforcement Learning},
  pages = {310-317},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967370},
  crossref = {conf/adprl/2011},
  author = {John W. Roberts and Ian R. Manchester and Russ Tedrake}
}
@inproceedings{conf/adprl/YaoSPZ14,
  title = {Pseudo-MDPs and factored linear action models},
  pages = {1-9},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010633},
  crossref = {conf/adprl/2014},
  author = {Hengshuai Yao and Csaba Szepesvári and Bernardo Avila Pires and Xinhua Zhang}
}
@inproceedings{conf/adprl/PetersK09,
  title = {Using reward-weighted imitation for robot Reinforcement Learning},
  pages = {226-232},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927549},
  crossref = {conf/adprl/2009},
  author = {Jan Peters 0001 and Jens Kober}
}
@inproceedings{conf/adprl/SongZ11,
  title = {N-step optimal time-invariant trajectory tracking control for a class of nonlinear systems},
  pages = {184-189},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967354},
  crossref = {conf/adprl/2011},
  author = {Ruizhuo Song and Huaguang Zhang}
}
@inproceedings{conf/adprl/AhmadzadehKC14,
  title = {Multi-objective reinforcement learning for AUV thruster failure recovery},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010621},
  crossref = {conf/adprl/2014},
  author = {Seyed Reza Ahmadzadeh and Petar Kormushev and Darwin G. Caldwell}
}
@inproceedings{conf/adprl/Feinberg09,
  title = {Adaptive computation of optimal nonrandomized policies in constrained average-reward MDPs},
  pages = {96-100},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927531},
  crossref = {conf/adprl/2009},
  author = {Eugene A. Feinberg}
}
@inproceedings{conf/adprl/HachiyaASP09,
  title = {Efficient data reuse in value function approximation},
  pages = {8-15},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927519},
  crossref = {conf/adprl/2009},
  author = {Hirotaka Hachiya and Takayuki Akiyama and Masashi Sugiyama and Jan Peters 0001}
}
@inproceedings{conf/adprl/Handa13,
  title = {On the coordination system for the dimensionality-reduced inputs of mario},
  pages = {170-176},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6615004},
  crossref = {conf/adprl/2013},
  author = {Hisashi Handa}
}
@inproceedings{conf/adprl/WangHX13,
  title = {A novel approach for constructing basis functions in approximate dynamic programming for feedback control},
  pages = {47-51},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614988},
  crossref = {conf/adprl/2013},
  author = {Jian Wang and Zhenhua Huang and Xin Xu}
}
@inproceedings{conf/adprl/ZhongT11,
  title = {Moving least-squares approximations for linearly-solvable MDP},
  pages = {218-225},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967383},
  crossref = {conf/adprl/2011},
  author = {Mingyuan Zhong and Emanuel Todorov}
}
@inproceedings{conf/adprl/AllenHM14,
  title = {Heuristics for multiagent reinforcement learning in decentralized decision problems},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010642},
  crossref = {conf/adprl/2014},
  author = {Martin W. Allen and David Hahn and Douglas C. MacFarland}
}
@inproceedings{conf/adprl/ErezS09,
  title = {Coupling perception and action using minimax optimal control},
  pages = {58-65},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927526},
  crossref = {conf/adprl/2009},
  author = {Tom Erez and William D. Smart}
}
@inproceedings{conf/adprl/JhaB14,
  title = {On-policy Q-learning for adaptive optimal control},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010649},
  crossref = {conf/adprl/2014},
  author = {Sumit Kumar Jha and Shubhendu Bhasin}
}
@inproceedings{conf/adprl/RichertSKKS09,
  title = {Integrating sporadic imitation in Reinforcement Learning robots},
  pages = {193-198},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927544},
  crossref = {conf/adprl/2009},
  author = {Willi Richert and Ulrich Scheller and Markus Koch and Bernd Kleinjohann and Claudius Stern}
}
@inproceedings{conf/adprl/FonteneauMWE11,
  title = {Active exploration by searching for experiments that falsify the computed control policy},
  pages = {40-47},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967364},
  crossref = {conf/adprl/2011},
  author = {Raphael Fonteneau and Susan A. Murphy and Louis Wehenkel and Damien Ernst}
}
@inproceedings{conf/adprl/WhitesonTTS11,
  title = {Protecting against evaluation overfitting in empirical reinforcement learning},
  pages = {120-127},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967363},
  crossref = {conf/adprl/2011},
  author = {Shimon Whiteson and Brian Tanner and Matthew E. Taylor and Peter Stone}
}
@inproceedings{conf/adprl/DengPM11,
  title = {Active learning for personalizing treatment},
  pages = {32-39},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967348},
  crossref = {conf/adprl/2011},
  author = {Kun Deng and Joelle Pineau and Susan A. Murphy}
}
@inproceedings{conf/adprl/LiuWS14,
  title = {Neural-network-based adaptive dynamic surface control for MIMO systems with unknown hysteresis},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010637},
  crossref = {conf/adprl/2014},
  author = {Lei Liu and Zhanshan Wang and Zhengwei Shen}
}
@inproceedings{conf/adprl/AkramizadehMA09,
  title = {Multiagent reinforcement learning in extensive form games with complete information},
  pages = {205-211},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927546},
  crossref = {conf/adprl/2009},
  author = {Ali Akramizadeh and Mohammad B. Menhaj and Ahmad Afshar}
}
@inproceedings{conf/adprl/KalyanakrishnanS11,
  title = {On learning with imperfect representations},
  pages = {17-24},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967379},
  crossref = {conf/adprl/2011},
  author = {Shivaram Kalyanakrishnan and Peter Stone}
}
@inproceedings{conf/adprl/DruganNM14,
  title = {Pareto Upper Confidence Bounds algorithms: An empirical study},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010620},
  crossref = {conf/adprl/2014},
  author = {Madalina M. Drugan and Ann Nowé and Bernard Manderick}
}
@inproceedings{conf/adprl/WieringWD14,
  title = {Model-based multi-objective reinforcement learning},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010622},
  crossref = {conf/adprl/2014},
  author = {Marco A. Wiering and Maikel Withagen and Madalina M. Drugan}
}
@inproceedings{conf/adprl/XuJ13,
  title = {Finite horizon stochastic optimal control of uncertain linear networked control system},
  pages = {24-30},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614985},
  crossref = {conf/adprl/2013},
  author = {Hao Xu and Sarangapani Jagannathan}
}
@inproceedings{conf/adprl/SogaK13,
  title = {A study on the efficiency of learning a robot controller in various environments},
  pages = {164-169},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6615003},
  crossref = {conf/adprl/2013},
  author = {Sachiko Soga and Ichiro Kobayashi}
}
@inproceedings{conf/adprl/MeyerDOS14,
  title = {Accelerated gradient temporal difference learning algorithms},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010611},
  crossref = {conf/adprl/2014},
  author = {Dominik Meyer and Remy Degenne and Ahmed Omrane and Hao Shen}
}
@inproceedings{conf/adprl/RexakisL11,
  title = {Directed exploration of policy space using support vector classifiers},
  pages = {112-119},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967389},
  crossref = {conf/adprl/2011},
  author = {Ioannis Rexakis and Michail G. Lagoudakis}
}
@inproceedings{conf/adprl/NiFHZX13,
  title = {Real-time tracking on adaptive critic design with uniformly ultimately bounded condition},
  pages = {39-46},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614987},
  crossref = {conf/adprl/2013},
  author = {Zhen Ni and Xiao Fang and Haibo He and Dongbin Zhao and Xin Xu}
}
@inproceedings{conf/adprl/WitschRGLR11,
  title = {Enhancing the episodic natural actor-critic algorithm by a regularisation term to stabilize learning of control structures},
  pages = {156-163},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967352},
  crossref = {conf/adprl/2011},
  author = {Andreas Witsch and Roland Reichle and Kurt Geihs and Sascha Lange and Martin A. Riedmiller}
}
@inproceedings{conf/adprl/VamvoudakisVL09,
  title = {Online policy iteration based algorithms to solve the continuous-time infinite horizon optimal control problem},
  pages = {36-41},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927523},
  crossref = {conf/adprl/2009},
  author = {Kyriakos G. Vamvoudakis and Draguna Vrabie and Frank L. Lewis}
}
@inproceedings{conf/adprl/PadmanabhanMH14,
  title = {Closed-loop control of anesthesia and mean arterial pressure using reinforcement learning},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010644},
  crossref = {conf/adprl/2014},
  author = {Regina Padmanabhan and Nader Meskin and Wassim M. Haddad}
}
@inproceedings{conf/adprl/GlaudePE14,
  title = {Subspace identification for predictive state representation by nuclear norm minimization},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010609},
  crossref = {conf/adprl/2014},
  author = {Hadrien Glaude and Olivier Pietquin and Cyrille Enderli}
}
@inproceedings{conf/adprl/DierksBJ11,
  title = {Near optimal control of mobile robot formations},
  pages = {234-241},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967369},
  crossref = {conf/adprl/2011},
  author = {Travis Dierks and Bryan Brenner and Sarangapani Jagannathan}
}
@inproceedings{conf/adprl/Handa11,
  title = {Structure search of probabilistic models and data correction for EDA-RL},
  pages = {332-337},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967388},
  crossref = {conf/adprl/2011},
  author = {Hisashi Handa}
}
@inproceedings{conf/adprl/HuhT09,
  title = {Real-time motor control using recurrent neural networks},
  pages = {42-49},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927524},
  crossref = {conf/adprl/2009},
  author = {Dongsung Huh and Emanuel Todorov}
}
@inproceedings{conf/adprl/DavarynejadAVB11,
  title = {Evolutionary value function approximation},
  pages = {151-155},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967349},
  crossref = {conf/adprl/2011},
  author = {Mohsen Davarynejad and Jelmer van Ast and Jos L. M. Vrancken and Jan van den Berg}
}
@inproceedings{conf/adprl/CuiZLK09,
  title = {Constrained optimal control of affine nonlinear discrete-time systems using GHJB method},
  pages = {16-21},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927520},
  crossref = {conf/adprl/2009},
  author = {Lili Cui and Huaguang Zhang and Derong Liu and Yongsu Kim}
}
@inproceedings{conf/adprl/LoweZ13,
  title = {Exploring the relationship of reward and punishment in reinforcement learning},
  pages = {140-147},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6615000},
  crossref = {conf/adprl/2013},
  author = {Robert Lowe and Tom Ziemke}
}
@inproceedings{conf/adprl/WangCLZ13,
  title = {Fault accommodation for complete synchronization of complex neural networks},
  pages = {200-205},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6615008},
  crossref = {conf/adprl/2013},
  author = {Zhanshan Wang and Fufei Chu and Hongjing Liang and Huaguang Zhang}
}
@inproceedings{conf/adprl/Corona-XelhuantziMS09,
  title = {Executing concurrent actions with multiple Markov decision processes},
  pages = {82-89},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927529},
  crossref = {conf/adprl/2009},
  author = {Elva Corona-Xelhuantzi and Eduardo F. Morales and Luis Enrique Sucar}
}
@inproceedings{conf/adprl/PazisL11,
  title = {Reinforcement learning in multidimensional continuous action spaces},
  pages = {97-104},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967381},
  crossref = {conf/adprl/2011},
  author = {Jason Pazis and Michail G. Lagoudakis}
}
@inproceedings{conf/adprl/CaiYX13,
  title = {A combined hierarchical reinforcement learning based approach for multi-robot cooperative target searching in complex unknown environments},
  pages = {52-59},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614989},
  crossref = {conf/adprl/2013},
  author = {Yifan Cai and Simon X. Yang and Xin Xu}
}
@inproceedings{conf/adprl/CuiLZ14,
  title = {An adaptive dynamic programming algorithm to solve optimal control of uncertain nonlinear systems},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010643},
  crossref = {conf/adprl/2014},
  author = {Xiaohong Cui and Yanhong Luo and Huaguang Zhang}
}
@inproceedings{conf/adprl/SimpkinsT09,
  title = {Practical numerical methods for stochastic optimal control of biological systems in continuous time and space},
  pages = {212-218},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927547},
  crossref = {conf/adprl/2009},
  author = {C. Alexander Simpkins and Emanuel Todorov}
}
@inproceedings{conf/adprl/QinZL13,
  title = {Adaptive optimal control for nonlinear discrete-time systems},
  pages = {13-18},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614983},
  crossref = {conf/adprl/2013},
  author = {Chunbin Qin and Huaguang Zhang and Yanhong Luo}
}
@inproceedings{conf/adprl/Todorov09,
  title = {Eigenfunction approximation methods for linearly-solvable optimal control problems},
  pages = {161-168},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927540},
  crossref = {conf/adprl/2009},
  author = {Emanuel Todorov}
}
@inproceedings{conf/adprl/LinDKSH14,
  title = {Adaptive dynamic programming-based optimal tracking control for nonlinear systems using general value iteration},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010638},
  crossref = {conf/adprl/2014},
  author = {Xiaofeng Lin and Qiang Ding and Weikai Kong and Chunning Song and Qingbao Huang}
}
@inproceedings{conf/adprl/MaP09,
  title = {A convergent recursive least squares approximate policy iteration algorithm for multi-dimensional Markov decision process with continuous state and action spaces},
  pages = {66-73},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927527},
  crossref = {conf/adprl/2009},
  author = {Jun Ma and Warren B. Powell}
}
@inproceedings{conf/adprl/LeeA14,
  title = {Convergent reinforcement learning control with neural networks and continuous action search},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010612},
  crossref = {conf/adprl/2014},
  author = {Minwoo Lee and Charles W. Anderson}
}
@inproceedings{conf/adprl/BusoniuESB11,
  title = {Approximate reinforcement learning: An overview},
  pages = {1-8},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967353},
  crossref = {conf/adprl/2011},
  author = {Lucian Busoniu and Damien Ernst and Bart De Schutter and Robert Babuska}
}
@inproceedings{conf/adprl/FuLXC13,
  title = {The second order temporal difference error for Sarsa(λ)},
  pages = {60-68},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614990},
  crossref = {conf/adprl/2013},
  author = {Qi-ming Fu and Quan Liu and Fei Xiao and Guixin Chen}
}
@inproceedings{conf/adprl/ZhangZLK09,
  title = {Neural-network-based reinforcement learning controller for nonlinear systems with non-symmetric dead-zone inputs},
  pages = {124-129},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927535},
  crossref = {conf/adprl/2009},
  author = {Xin Zhang and Huaguang Zhang and Derong Liu and Yongsu Kim}
}
@inproceedings{conf/adprl/LauSR13,
  title = {A reinforcement learning algorithm developed to model GenCo strategic bidding behavior in multidimensional and continuous state and action spaces},
  pages = {116-123},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614997},
  crossref = {conf/adprl/2013},
  author = {A. Y. F. Lau and Dipti Srinivasan and Thomas Reindl}
}
@proceedings{conf/adprl/2013,
  title = {Proceedings of the 2013 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning, ADPRL 2013, IEEE Symposium Series on Computational Intelligence (SSCI), 16-19 April 2013, Singapore},
  isbn = {978-1-4673-5925-2},
  publisher = {IEEE},
  year = {2013},
  url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6596003},
  booktitle = {ADPRL},
  author = {}
}
@inproceedings{conf/adprl/LuoSZ13,
  title = {An integrated design for intensified direct heuristic dynamic programming},
  pages = {183-190},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6615006},
  crossref = {conf/adprl/2013},
  author = {Xiong Luo and Jennie Si and Yuchao Zhou}
}
@inproceedings{conf/adprl/EdwardsP11,
  title = {Higher order Q-Learning},
  pages = {128-134},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967385},
  crossref = {conf/adprl/2011},
  author = {Ashley Edwards and William M. Pottenger}
}
@inproceedings{conf/adprl/CsajiKV14,
  title = {Adaptive aggregated predictions for renewable energy systems},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010625},
  crossref = {conf/adprl/2014},
  author = {Balázs Csanád Csáji and András Kovács and József Váncza}
}
@inproceedings{conf/adprl/GuzeyXJ14,
  title = {Neural network-based adaptive optimal consensus control of leaderless networked mobile robots},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010648},
  crossref = {conf/adprl/2014},
  author = {Haci Mehmet Guzey and Hao Xu and Sarangapani Jagannathan}
}
@inproceedings{conf/adprl/GosaviMH11,
  title = {Model-building semi-Markov adaptive critics},
  pages = {170-175},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967374},
  crossref = {conf/adprl/2011},
  author = {Abhijit Gosavi and Susan L. Murray and Jiaqiao Hu}
}
@inproceedings{conf/adprl/LeeDP13,
  title = {Bias-corrected Q-learning to control max-operator bias in Q-learning},
  pages = {93-99},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614994},
  crossref = {conf/adprl/2013},
  author = {Donghun Lee and Boris Defourny and Warren B. Powell}
}
@inproceedings{conf/adprl/WieringH09,
  title = {The QV family compared to other reinforcement learning algorithms},
  pages = {101-108},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927532},
  crossref = {conf/adprl/2009},
  author = {Marco A. Wiering and Hado van Hasselt}
}
@inproceedings{conf/adprl/LinLSS09,
  title = {Neuro-controller of cement rotary kiln temperature with adaptive critic designs},
  pages = {238-242},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927551},
  crossref = {conf/adprl/2009},
  author = {Xiaofeng Lin and Tangbo Liu and Shaojian Song and Chunning Song}
}
@inproceedings{conf/adprl/TodorovT09,
  title = {Iterative local dynamic programming},
  pages = {90-95},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927530},
  crossref = {conf/adprl/2009},
  author = {Emanuel Todorov and Yuval Tassa}
}
@inproceedings{conf/adprl/JiangPPSS14,
  title = {A comparison of approximate dynamic programming techniques on benchmark energy storage problems: Does anything work?},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010626},
  crossref = {conf/adprl/2014},
  author = {Daniel R. Jiang and Thuy V. Pham and Warren B. Powell and Daniel F. Salas and Warren R. Scott}
}
@inproceedings{conf/adprl/VamvoudakisVL11,
  title = {Online adaptive learning of optimal control solutions using integral reinforcement learning},
  pages = {250-257},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967359},
  crossref = {conf/adprl/2011},
  author = {Kyriakos G. Vamvoudakis and Draguna Vrabie and Frank L. Lewis}
}
@inproceedings{conf/adprl/PazisL09,
  title = {Learning continuous-action control policies},
  pages = {169-176},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927541},
  crossref = {conf/adprl/2009},
  author = {Jason Pazis and Michail G. Lagoudakis}
}
@inproceedings{conf/adprl/TassaT11,
  title = {High-order local dynamic programming},
  pages = {70-75},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967350},
  crossref = {conf/adprl/2011},
  author = {Yuval Tassa and Emanuel Todorov}
}
@inproceedings{conf/adprl/El-Alfy11,
  title = {A reinforcement learning approach for sequential mastery testing},
  pages = {295-301},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967390},
  crossref = {conf/adprl/2011},
  author = {El-Sayed M. El-Alfy}
}
@proceedings{conf/adprl/2014,
  title = {2014 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning, ADPRL 2014, Orlando, FL, USA, December 9-12, 2014},
  booktitle = {ADPRL},
  publisher = {IEEE},
  year = {2014},
  isbn = {978-1-4799-4553-5},
  url = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7000183},
  author = {}
}
@inproceedings{conf/adprl/LuoX14,
  title = {ADP-based optimal control for a class of nonlinear discrete-time systems with inequality constraints},
  pages = {1-5},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010639},
  crossref = {conf/adprl/2014},
  author = {Yanhong Luo and Geyang Xiao}
}
@inproceedings{conf/adprl/RyzhovP11,
  title = {Bayesian active learning with basis functions},
  pages = {143-150},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967365},
  crossref = {conf/adprl/2011},
  author = {Ilya O. Ryzhov and Warren B. Powell}
}
@inproceedings{conf/adprl/ParisiPSBR14,
  title = {Policy gradient approaches for multi-objective sequential decision making: A comparison},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010618},
  crossref = {conf/adprl/2014},
  author = {Simone Parisi and Matteo Pirotta and Nicola Smacchia and Luca Bascetta and Marcello Restelli}
}
@inproceedings{conf/adprl/HaykinAF14,
  title = {Cognitive control in cognitive dynamic systems: A new way of thinking inspired by the brain},
  pages = {1-7},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010623},
  crossref = {conf/adprl/2014},
  author = {Simon Haykin and Ashkan Amiri and Mehdi Fatemi}
}
@inproceedings{conf/adprl/HuD14,
  title = {Near-optimality bounds for greedy periodic policies with application to grid-level storage},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010627},
  crossref = {conf/adprl/2014},
  author = {Yuhai Hu and Boris Defourny}
}
@inproceedings{conf/adprl/FujitaU14,
  title = {Reinforcement learning-based optimal control considering L computation time delay of linear discrete-time systems},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010632},
  crossref = {conf/adprl/2014},
  author = {Taishi Fujita and Toshimitu Ushio}
}
@inproceedings{conf/adprl/ZargarzadehJD11,
  title = {Online near optimal control of unknown nonaffine systems with application to HCCI engines},
  pages = {258-263},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967382},
  crossref = {conf/adprl/2011},
  author = {Hassan Zargarzadeh and Sarangapani Jagannathan and James A. Drallmeier}
}
@inproceedings{conf/adprl/Bertsekas09,
  title = {A unified framework for temporal difference methods},
  pages = {1-7},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927518},
  crossref = {conf/adprl/2009},
  author = {Dimitri P. Bertsekas}
}
@inproceedings{conf/adprl/ChakravortyE11,
  title = {Information space receding horizon control},
  pages = {302-309},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967362},
  crossref = {conf/adprl/2011},
  author = {Suman Chakravorty and R. Scott Erwin}
}
@inproceedings{conf/adprl/BusoniuMSB11,
  title = {Optimistic planning for sparsely stochastic systems},
  pages = {48-55},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967375},
  crossref = {conf/adprl/2011},
  author = {Lucian Busoniu and Rémi Munos and Bart De Schutter and Robert Babuska}
}
@inproceedings{conf/adprl/BusoniuESB09,
  title = {Policy search with cross-entropy optimization of basis functions},
  pages = {153-160},
  year = {2009},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2009.4927539},
  crossref = {conf/adprl/2009},
  author = {Lucian Busoniu and Damien Ernst and Bart De Schutter and Robert Babuska}
}
@inproceedings{conf/adprl/Al-TalabiS14,
  title = {A two stage learning technique for dual learning in the pursuit-evasion differential game},
  pages = {1-8},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010641},
  crossref = {conf/adprl/2014},
  author = {Ahmad A. Al-Talabi and Howard M. Schwartz}
}
@inproceedings{conf/adprl/JungEM13,
  title = {Optimized look-ahead trees: Extensions to large and continuous action spaces},
  pages = {85-92},
  year = {2013},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2013.6614993},
  crossref = {conf/adprl/2013},
  author = {Tobias Jung and Damien Ernst and Francis Maes}
}
@inproceedings{conf/adprl/CuiZZL11,
  title = {Data-based adaptive critic design for discrete-time zero-sum games using output feedback},
  pages = {190-195},
  year = {2011},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2011.5967351},
  crossref = {conf/adprl/2011},
  author = {Lili Cui and Huaguang Zhang and Xin Zhang and Yanhong Luo}
}
@inproceedings{conf/adprl/ZhuZ14,
  title = {A data-based online reinforcement learning algorithm with high-efficient exploration},
  pages = {1-6},
  year = {2014},
  booktitle = {ADPRL},
  doi = {10.1109/ADPRL.2014.7010631},
  crossref = {conf/adprl/2014},
  author = {Yuanheng Zhu and Dongbin Zhao}
}
